{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLwafpP56TrdRld47W9Ced",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tom4toPot/NLP_toys/blob/main/Simple_Demo_Word_Window_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demo is mostly a rewrite version of the tutorial [Stanford CS 224N](https://colab.research.google.com/drive/13HGy3-uIIy1KD_WFhG4nVrxJC-3nUUkP?usp=sharing), with minor edition and some analysis."
      ],
      "metadata": {
        "id": "gG6j-v6BJQaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem description\n",
        "build a simple classifier input fixed number of words and output whether the center word is a LOCATION."
      ],
      "metadata": {
        "id": "MHdoWUu4JckW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh4bdYi-IOPp"
      },
      "outputs": [],
      "source": [
        "# Our raw data, which consists of sentences\n",
        "corpus = [\n",
        "          \"We always come to Paris\",\n",
        "          \"The professor is from Australia\",\n",
        "          \"I live in Stanford\",\n",
        "          \"He comes from Taiwan\",\n",
        "          \"The capital of Turkey is Ankara\"\n",
        "         ]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing\n",
        "* special characters\n",
        "* tokenization\n",
        "* lowercasing"
      ],
      "metadata": {
        "id": "rLlaeHlcI3w6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "s = \"We! always come to Paris.12\" # only keep letters\n",
        "re.sub(r'[^A-Za-z ]+', '', s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8lvMycGeNWIs",
        "outputId": "7e09e2a7-22d1-49e0-e10e-afdf1a158426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'We always come to Paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple lowercase all and split(by space) into words\n",
        "def preprocess_sentence(sentence):\n",
        "  return re.sub(r'[^A-Za-z ]+', '',sentence).lower().split()\n",
        "\n",
        "train_sentences = [preprocess_sentence(sent) for sent in corpus]\n",
        "train_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA_Vu4HAIhsp",
        "outputId": "23810601-c5fb-41d6-a944-d597160391df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['we', 'always', 'come', 'to', 'paris'],\n",
              " ['the', 'professor', 'is', 'from', 'australia'],\n",
              " ['i', 'live', 'in', 'stanford'],\n",
              " ['he', 'comes', 'from', 'taiwan'],\n",
              " ['the', 'capital', 'of', 'turkey', 'is', 'ankara']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating labels for training data:\n",
        "* if the word is a LOCATION, label 1\n",
        "* else, label 0."
      ],
      "metadata": {
        "id": "Exqq-cTUJ3SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set of locations that appear in our corpus\n",
        "locations = set([\"australia\", \"ankara\", \"paris\", \"stanford\", \"taiwan\", \"turkey\"])\n",
        "\n",
        "# Our train labels\n",
        "train_labels = [[1 if word in locations else 0 for word in sent] for sent in train_sentences]\n",
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp3KuwcpIwNd",
        "outputId": "078e4afa-6964-4473-ebb6-068645b02bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build a dictionary"
      ],
      "metadata": {
        "id": "YZN8qbP3KPlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set(w for s in train_sentences for w in s)\n",
        "vocabulary.add(\"<unk>\") # add the unknown token\n",
        "vocabulary.add(\"<pad>\") # add the padding for window\n",
        "len(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiHZYscPKFFj",
        "outputId": "d66bfa80-7a97-454a-ea06-9b7dfc8fc09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# notice that the total window size is 2*window_size+1\n",
        "def pad_window(sentence, window_size, pad_token = \"<pad>\"):\n",
        "  window = [pad_token] * window_size\n",
        "  return window + sentence + window\n",
        "\n",
        "pad_window(train_sentences[1], window_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdPvpTc4Klfb",
        "outputId": "673ff861-580f-496b-c99a-a84ea9771bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>',\n",
              " '<pad>',\n",
              " 'the',\n",
              " 'professor',\n",
              " 'is',\n",
              " 'from',\n",
              " 'australia',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_word = sorted(list(vocabulary)) \n",
        "\n",
        "word_to_idx = {word: idx for idx, word in enumerate(idx_to_word)}\n",
        "\n",
        "def convert_token_to_idx(sentence, word_to_idx):\n",
        "  return [word_to_idx.get(token, word_to_idx[\"<unk>\"]) for token in sentence]\n",
        "\n",
        "print(f\"From token list to indices: {convert_token_to_idx(train_sentences[0], word_to_idx)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YegZN_uULYnY",
        "outputId": "e22c115a-5cc0-453c-90d4-d662f031669e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From token list to indices: [22, 2, 6, 20, 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an embedding table\n",
        "\n",
        "with `nn.Embedding(num_words, embedding_dimension)`"
      ],
      "metadata": {
        "id": "zF_Xz1wmPVq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "hjDifv0QPiiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 5 # embedding dimension is 5\n",
        "embeds = nn.Embedding(len(vocabulary), embedding_dim) # create an embedding table\n",
        "\n",
        "list(embeds.named_parameters()) # current embeddings for each word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntBOnPAHOamh",
        "outputId": "0822ea47-e716-4e2e-e574-7770155f876c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weight', Parameter containing:\n",
              "  tensor([[ 0.4098, -2.4334,  0.3162,  0.2969,  0.1592],\n",
              "          [-1.2451, -2.5765, -1.6796,  0.7516, -0.7779],\n",
              "          [-1.8351,  0.0980, -0.0330,  0.8593, -1.9052],\n",
              "          [ 1.2093, -0.3367, -0.8238, -0.7045, -1.0983],\n",
              "          [ 0.6358, -0.2363,  1.3068, -1.1299,  0.5609],\n",
              "          [ 0.3433,  0.2411, -0.7985,  1.3960,  0.9617],\n",
              "          [-0.3141, -0.1031,  0.1062,  1.4690,  0.8606],\n",
              "          [-0.2018, -0.7244,  0.3078, -0.0094,  1.0512],\n",
              "          [ 2.1535,  1.1693,  0.0591,  0.3641,  0.2246],\n",
              "          [-0.7594, -0.4067, -0.9263,  1.6237, -0.7148],\n",
              "          [-0.4435,  0.3144,  0.1890,  1.3535,  0.0840],\n",
              "          [-0.2986,  2.7067,  0.2760,  0.3518, -1.2447],\n",
              "          [ 0.2308,  0.5228, -1.0962, -0.2783,  0.3644],\n",
              "          [ 0.3816, -0.8633, -1.0878, -0.7087,  0.1341],\n",
              "          [-1.9324,  0.9979, -4.0401, -0.3142, -0.2032],\n",
              "          [ 0.1987,  0.3541,  0.0593, -1.7592,  0.5147],\n",
              "          [ 0.3165, -0.1248,  0.9690, -1.4124,  0.1278],\n",
              "          [ 0.0466,  0.2293,  0.1853,  0.9252, -1.2548],\n",
              "          [ 0.6421, -0.0980, -0.0566, -2.0558, -0.0834],\n",
              "          [ 0.1235, -0.1304, -1.2258,  1.0515, -0.9185],\n",
              "          [-0.1147,  0.2625, -0.7694,  0.3040, -0.3957],\n",
              "          [-1.0098, -2.3781, -0.1872, -0.8269,  0.4008],\n",
              "          [-1.0670,  0.5430, -0.9485,  0.1729, -1.1032]], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embeddings for words (if we want to do something later...)\n",
        "indices = torch.tensor([word_to_idx[v] for v in [\"paris\", \"ankara\"]], dtype=torch.long)\n",
        "embeddings = embeds(indices)\n",
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARTCRQWHQTdC",
        "outputId": "2355a2fb-e28b-4bba-a5bb-341dd3d682fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1987,  0.3541,  0.0593, -1.7592,  0.5147],\n",
              "        [ 1.2093, -0.3367, -0.8238, -0.7045, -1.0983]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching Sentences\n",
        "\n",
        "`DataLoader(data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)`\n",
        "\n",
        "in `collate_fn`, we can put a custom function."
      ],
      "metadata": {
        "id": "5HwhqHAzRRX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "scmsfaJTRKG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch, window_size, word_to_idx):\n",
        "  x, y = zip(*batch)\n",
        "\n",
        "  def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
        "    window = [pad_token]*window_size\n",
        "    return window + sentence +window\n",
        "\n",
        "  x = [pad_window(s, window_size=window_size) for s in x]\n",
        "\n",
        "  def convert_token_to_idx(sentence, word_to_idx):\n",
        "    return [word_to_idx.get(token, word_to_idx[\"<unk>\"]) for token in sentence] \n",
        "    # use get here to have a default value for words not in dictionary\n",
        "  \n",
        "  x = [convert_token_to_idx(s, word_to_idx) for s in x]\n",
        "  pad_token_idx = word_to_idx[\"<pad>\"]\n",
        "\n",
        "  # pad all sentences to equal length\n",
        "  x = [torch.LongTensor(x_i) for x_i in x]\n",
        "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_idx)\n",
        "  \n",
        "  lengths = [len(label) for label in y]\n",
        "  lengths = torch.LongTensor(lengths)\n",
        "\n",
        "  y = [torch.LongTensor(y_i) for y_i in y]\n",
        "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=pad_token_idx)\n",
        "\n",
        "  return x_padded, y_padded, lengths\n"
      ],
      "metadata": {
        "id": "JDZLfkyvSHWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "data = list(zip(train_sentences, train_labels))\n",
        "batch_size = 2\n",
        "shuffle = True\n",
        "window_size = 2\n",
        "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_idx=word_to_idx)\n",
        "\n",
        "# instantiate\n",
        "loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
        "\n",
        "counter = 0\n",
        "for batched_x, batched_y, batched_lengths in loader:\n",
        "  print(f\"Iteration {counter}\")\n",
        "  print(\"Batched Input:\")\n",
        "  print(batched_x)\n",
        "  print(\"Batched Labels:\")\n",
        "  print(batched_y)\n",
        "  print(\"Batched Lengths:\")\n",
        "  print(batched_lengths)\n",
        "  print(\"\")\n",
        "  counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmBDU_f_nHkh",
        "outputId": "56b2712a-0d4b-4941-a741-37d029e20fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0\n",
            "Batched Input:\n",
            "tensor([[ 0,  0, 22,  2,  6, 20, 15,  0,  0,  0],\n",
            "        [ 0,  0, 19,  5, 14, 21, 12,  3,  0,  0]])\n",
            "Batched Labels:\n",
            "tensor([[0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 1, 0, 1]])\n",
            "Batched Lengths:\n",
            "tensor([5, 6])\n",
            "\n",
            "Iteration 1\n",
            "Batched Input:\n",
            "tensor([[ 0,  0, 19, 16, 12,  8,  4,  0,  0],\n",
            "        [ 0,  0,  9,  7,  8, 18,  0,  0,  0]])\n",
            "Batched Labels:\n",
            "tensor([[0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 1, 0]])\n",
            "Batched Lengths:\n",
            "tensor([5, 4])\n",
            "\n",
            "Iteration 2\n",
            "Batched Input:\n",
            "tensor([[ 0,  0, 10, 13, 11, 17,  0,  0]])\n",
            "Batched Labels:\n",
            "tensor([[0, 0, 0, 1]])\n",
            "Batched Lengths:\n",
            "tensor([4])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create windows using unfold function\n",
        "chunk = batched_x.unfold(1, window_size*2+1, 1)\n",
        "print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qingGvXEnoo-",
        "outputId": "bced4aec-823a-428f-d438-fa12dbeee1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  0, 10, 13, 11],\n",
            "         [ 0, 10, 13, 11, 17],\n",
            "         [10, 13, 11, 17,  0],\n",
            "         [13, 11, 17,  0,  0]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "KicUpquDprCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordWindowClassifier(nn.Module):\n",
        "  def __init__(self, param, vocab_size, pad_idx=0):\n",
        "    super(WordWindowClassifier, self).__init__()\n",
        "\n",
        "    self.window_size = param[\"window_size\"]\n",
        "    self.embed_dim = param[\"embed_dim\"]\n",
        "    self.hidden_dim = param[\"hidden_dim\"]\n",
        "    self.freeze_embeddings = param[\"freeze_embeddings\"]\n",
        "\n",
        "    # embedding layer\n",
        "    self.embeds = nn.Embedding(vocab_size, self.embed_dim, padding_idx=pad_idx)\n",
        "    # if freeze_embeddings, set require grad to false\n",
        "    if self.freeze_embeddings:\n",
        "      self.embed_layer.weight.requires_grad = False \n",
        "\n",
        "    \"\"\" Hidden Layer\n",
        "    \"\"\"\n",
        "    full_window_size = 2*window_size+1\n",
        "    self.hidden_layer = nn.Sequential(\n",
        "        nn.Linear(full_window_size * self.embed_dim, self.hidden_dim),\n",
        "        nn.Tanh()\n",
        "    )  \n",
        "\n",
        "    \"\"\" Output Layer\n",
        "    \"\"\"\n",
        "    self.output_layer = nn.Linear(self.hidden_dim, 1)\n",
        "\n",
        "    self.prob = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    B, L = inputs.size()\n",
        "\n",
        "    token_windows = inputs.unfold(1, 2*self.window_size+1, 1)\n",
        "    _,adjusted_length,_ = token_windows.size()\n",
        "\n",
        "    assert token_windows.size() == (B, adjusted_length, 2*self.window_size+1)\n",
        "\n",
        "    # embedding layer\n",
        "    embedded_windows = self.embeds(token_windows)\n",
        "\n",
        "    # reshape to combine dim of windows and embeddings\n",
        "    embedded_windows = embedded_windows.view(B, adjusted_length, -1)\n",
        "\n",
        "    layer_1 = self.hidden_layer(embedded_windows)\n",
        "\n",
        "    output = self.output_layer(layer_1)\n",
        "\n",
        "    output = self.prob(output)\n",
        "    output = output.view(B, -1)\n",
        "    \n",
        "    return output"
      ],
      "metadata": {
        "id": "uywiOvvyohFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "4yyh1LLPw8pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(zip(train_sentences, train_labels))\n",
        "batch_size = 2\n",
        "shuffle = True\n",
        "window_size = 2\n",
        "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_idx=word_to_idx)\n",
        "\n",
        "loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn\n",
        "                    )\n",
        "\n",
        "model_param = {\n",
        "    \"batch_size\": 4,\n",
        "    \"window_size\": 2,\n",
        "    \"embed_dim\": 25,\n",
        "    \"hidden_dim\": 25,\n",
        "    \"freeze_embeddings\": False\n",
        "}\n",
        "\n",
        "vocab_size = len(word_to_idx)\n",
        "model = WordWindowClassifier(model_param, vocab_size)\n",
        "\n",
        "# optimizer\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# loss function\n",
        "def loss_function(batch_outputs, batch_labels, batch_lengths):\n",
        "  bceloss = nn.BCELoss()\n",
        "  loss = bceloss(batch_outputs, batch_labels.float())\n",
        "\n",
        "  loss = loss/batch_labels.sum().float()\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "yrOTkWJFw9kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(loss_function, optimizer, model, loader):\n",
        "\n",
        "  total_loss = 0\n",
        "  for batch_inputs, batch_labels, batch_lengths in loader:\n",
        "    # clear gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass\n",
        "    outputs = model.forward(batch_inputs)\n",
        "    # compute loss\n",
        "    loss = loss_function(outputs, batch_labels, batch_lengths)\n",
        "    # gradients\n",
        "    loss.backward()\n",
        "    # update params\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss\n",
        "\n",
        "def train(loss_function, optimizer, model, loader, num_epochs=10000):\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = train_epoch(loss_function, optimizer, model, loader)\n",
        "    if epoch%100 == 0:\n",
        "      print(epoch_loss)"
      ],
      "metadata": {
        "id": "OGyzdwn5z1T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "train(loss_function, optimizer, model, loader, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWxSfUfg0qrS",
        "outputId": "76c3ffe5-3344-4c66-dcb7-604102dcd2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.002883558685425669\n",
            "0.0028394981054589152\n",
            "0.002706396917346865\n",
            "0.0038161433476489037\n",
            "0.0027932398952543736\n",
            "0.0022353382664732635\n",
            "0.003413549275137484\n",
            "0.002417302515823394\n",
            "0.0021423909347504377\n",
            "0.002302502456586808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions"
      ],
      "metadata": {
        "id": "btDn4m1v1srP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_corpus = [\"She comes from Paris\",\n",
        "               \"She comes from China\"]\n",
        "test_sentences = [preprocess_sentence(sent) for sent in test_corpus]\n",
        "test_labels = [[0, 0, 0, 1],[0, 0, 0, 1]]\n",
        "\n",
        "test_data = list(zip(test_sentences, test_labels))\n",
        "batch_size = 1\n",
        "shuffle = False\n",
        "window_size = 2\n",
        "collate_fn = partial(custom_collate_fn, window_size=2, word_to_idx=word_to_idx)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, \n",
        "                                           batch_size=1, \n",
        "                                           shuffle=False, \n",
        "                                           collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "bxM-fIBZ02Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_instances, labels, _ in test_loader:\n",
        "  outputs = model.forward(test_instances)\n",
        "  print(labels)\n",
        "  print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPczPPab2PTk",
        "outputId": "6891d9fe-2435-438a-c3d0-305d6cd18b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 1]])\n",
            "tensor([[8.4251e-03, 1.5757e-04, 1.6452e-04, 9.9932e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0, 0, 0, 1]])\n",
            "tensor([[8.4251e-03, 7.1489e-04, 3.7368e-04, 9.9879e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result analysis"
      ],
      "metadata": {
        "id": "02PYCJhf2jAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_probs = []\n",
        "for test_instances, labels, _ in test_loader:\n",
        "  outputs = model.forward(test_instances)\n",
        "  predict_probs.append(outputs.detach().numpy())\n",
        "  print(labels)\n",
        "  print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFAxCgnw2oDN",
        "outputId": "7e3de434-e533-4a0b-bb90-640988a49915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 1]])\n",
            "tensor([[8.4251e-03, 1.5757e-04, 1.6452e-04, 9.9932e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0, 0, 0, 1]])\n",
            "tensor([[8.4251e-03, 7.1489e-04, 3.7368e-04, 9.9879e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def colorize(words, color_array):\n",
        "    cmap=matplotlib.cm.RdYlGn\n",
        "    template = '<span class=\"barcode\"; style=\"color: white; background-color: {}\">{}</span>'\n",
        "    colored_string = ''\n",
        "    for word, color in zip(words, color_array):\n",
        "        color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n",
        "        colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n",
        "    return colored_string\n",
        "\n",
        "# # or simply save in an html file and open in browser\n",
        "# with open('colorize.html', 'w') as f:\n",
        "#     f.write(s)"
      ],
      "metadata": {
        "id": "SPz8IloL3wsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence, prediction in zip(test_sentences, predict_probs):\n",
        "  s = colorize(sentence, prediction[0])\n",
        "  display(HTML(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "13RJqsXI4rNj",
        "outputId": "799ecf7e-7bc7-4590-840e-90f5394de990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"barcode\"; style=\"color: white; background-color: #a90426\">&nbspshe&nbsp</span><span class=\"barcode\"; style=\"color: white; background-color: #a50026\">&nbspcomes&nbsp</span><span class=\"barcode\"; style=\"color: white; background-color: #a50026\">&nbspfrom&nbsp</span><span class=\"barcode\"; style=\"color: white; background-color: #006837\">&nbspparis&nbsp</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"barcode\"; style=\"color: white; background-color: #a90426\">&nbspshe&nbsp</span><span class=\"barcode\"; style=\"color: white; background-color: #a50026\">&nbspcomes&nbsp</span><span class=\"barcode\"; style=\"color: white; background-color: #a50026\">&nbspfrom&nbsp</span><span class=\"barcode\"; style=\"color: white; background-color: #006837\">&nbspchina&nbsp</span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From those 2 simple test sentences, we could see the toy classifier does well on both the LOCATION words in dictionary(\"Paris\") and not in the dictionary(\"China\")."
      ],
      "metadata": {
        "id": "SHhF5hQT8NSF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_ibelEJ8bZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}